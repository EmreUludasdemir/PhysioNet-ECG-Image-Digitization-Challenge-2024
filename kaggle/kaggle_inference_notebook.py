"""
PhysioNet ECG Image Digitization - Kaggle Inference Script (Timeout Optimized)
===============================================================================

Kaggle timeout sorununu Ã§Ã¶zmek iÃ§in optimize edilmiÅŸ versiyon.
Her adÄ±mda Ã§Ä±ktÄ± vererek session'Ä±n kapanmasÄ±nÄ± engeller.

Author: PhysioNet Challenge Team
Version: 2.0 (Timeout-Safe)
"""

import os
import sys
from pathlib import Path
import subprocess
import time as time_module
from datetime import datetime

# BaÅŸlangÄ±Ã§ zamanÄ±
START_TIME = time_module.time()

def log(message, level="INFO"):
    """Zaman damgalÄ± log mesajÄ± (timeout'u engellemek iÃ§in)"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {level}: {message}", flush=True)

def heartbeat(message="Still working..."):
    """Heartbeat mesajÄ± - Kaggle timeout'unu engeller"""
    print(f"ğŸ’“ {message}", flush=True)

print("=" * 80)
print("PhysioNet ECG Image Digitization - Kaggle Inference Pipeline v2.0")
print("=" * 80)
print()

# ============================================================================
# STEP 1: Setup ve Kurulum
# ============================================================================
log("STEP 1: Projeyi GitHub'dan klonlama ve kurulum", "START")
print("-" * 80)

# Eski/bozuk dizinleri temizle (cache problemi iÃ§in)
project_dir = '/kaggle/working/PhysioNet-ECG-Image-Digitization-Challenge-2024'
if os.path.exists(project_dir):
    log("Eski proje dizini tespit edildi, temizleniyor...")
    import shutil
    try:
        shutil.rmtree(project_dir)
        log("âœ“ Eski dizin temizlendi")
    except Exception as e:
        log(f"âš ï¸ Temizleme uyarÄ±sÄ±: {e}", "WARNING")

# GitHub'dan fresh clone
log("GitHub'dan klonlanÄ±yor...")
result = subprocess.run([
    'git', 'clone',
    'https://github.com/EmreUludasdemir/PhysioNet-ECG-Image-Digitization-Challenge-2024.git'
], cwd='/kaggle/working', capture_output=True, text=True)

if result.returncode != 0:
    log(f"âŒ Clone hatasÄ±: {result.stderr}", "ERROR")
    sys.exit(1)

log("âœ“ Klonlama tamamlandÄ±")

# Proje dizinine geÃ§
os.chdir(project_dir)
log(f"âœ“ Ã‡alÄ±ÅŸma dizini: {os.getcwd()}")

# Branch'i checkout et
log("Branch kontrol ediliyor...")
subprocess.run(['git', 'checkout', 'claude/physionet-ecg-digitization-011CUq26jaEWm593owfiQqvq'],
               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
log("âœ“ Branch: claude/physionet-ecg-digitization-011CUq26jaEWm593owfiQqvq")

# Gerekli paketleri yÃ¼kle
log("Gerekli paketler yÃ¼kleniyor...")
packages = [
    'segmentation-models-pytorch',
    'timm',
    'albumentations',
    'opencv-python-headless',
    'scikit-image',
    'scipy',
    'pandas',
    'tqdm'
]

for i, package in enumerate(packages, 1):
    heartbeat(f"YÃ¼kleniyor ({i}/{len(packages)}): {package}")
    subprocess.run(['pip', 'install', '-q', package],
                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    log(f"âœ“ {package}")

log("âœ… Kurulum tamamlandÄ±!", "SUCCESS")
print()

# NumPy 2.x uyumluluk sorunu iÃ§in downgrade
log("NumPy versiyonu kontrol ediliyor...")
heartbeat("NumPy 1.x'e downgrade yapÄ±lÄ±yor (matplotlib uyumluluÄŸu iÃ§in)...")
subprocess.run(
    ['pip', 'install', 'numpy<2.0', '--force-reinstall', '-q'],
    stdout=subprocess.DEVNULL,
    stderr=subprocess.DEVNULL
)
log("âœ“ NumPy downgrade tamamlandÄ±")
print()


# ============================================================================
# STEP 2: Import'lar ve KonfigÃ¼rasyon
# ============================================================================
log("STEP 2: ModÃ¼lleri yÃ¼kleme", "START")
print("-" * 80)

# Path ekle
sys.path.insert(0, '/kaggle/working/PhysioNet-ECG-Image-Digitization-Challenge-2024')

# Import'lar
heartbeat("Numpy ve temel kÃ¼tÃ¼phaneler yÃ¼kleniyor...")
import numpy as np
import pandas as pd
heartbeat("Matplotlib yÃ¼kleniyor...")
import matplotlib
matplotlib.use('Agg')  # GUI olmadan Ã§alÄ±ÅŸ
import matplotlib.pyplot as plt
heartbeat("CV2 ve gÃ¶rÃ¼ntÃ¼ iÅŸleme kÃ¼tÃ¼phaneleri yÃ¼kleniyor...")
import cv2
import warnings
warnings.filterwarnings('ignore')
heartbeat("PyTorch yÃ¼kleniyor...")
import torch
heartbeat("Tqdm yÃ¼kleniyor...")
from tqdm import tqdm

log("âœ“ Temel kÃ¼tÃ¼phaneler yÃ¼klendi")

# Proje modÃ¼lleri
try:
    heartbeat("Proje modÃ¼lleri yÃ¼kleniyor...")
    from src.config import get_config
    from src.inference import ECGInferencePipeline
    from src.data_preprocessing import ECGImagePreprocessor
    from src.evaluation import ECGEvaluator
    from src.segmentation_model import create_model
    from src.vectorization import ECGVectorizer
    log("âœ… TÃ¼m modÃ¼ller baÅŸarÄ±yla yÃ¼klendi!", "SUCCESS")
except ImportError as e:
    log(f"âŒ ModÃ¼l yÃ¼kleme hatasÄ±: {e}", "ERROR")
    sys.exit(1)

# Device kontrolÃ¼
device = 'cuda' if torch.cuda.is_available() else 'cpu'
log(f"ğŸ”§ Device: {device.upper()}")
if device == 'cuda':
    log(f"   GPU: {torch.cuda.get_device_name(0)}")
    log(f"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

# Config yÃ¼kle
config = get_config()
log("âœ“ KonfigÃ¼rasyon yÃ¼klendi")
print()


# ============================================================================
# STEP 3: Test Verisi ve Sample Submission KontrolÃ¼
# ============================================================================
log("STEP 3: Test verisi ve sample_submission.csv kontrol", "START")
print("-" * 80)

# OlasÄ± input lokasyonlarÄ± (yarÄ±ÅŸmanÄ±n farklÄ± isimleri iÃ§in)
possible_input_dirs = [
    '/kaggle/input/physionet-ecg-image-digitization',
    '/kaggle/input/physionet-ecg-digitization-challenge-2024',
    '/kaggle/input/physionet-challenge-2024',
    '/kaggle/input',
]

# Sample submission dosyasÄ±nÄ± bul
sample_submission_path = None
test_data_path = None
competition_input_dir = None

for input_dir in possible_input_dirs:
    heartbeat(f"Kontrol ediliyor: {input_dir}")
    if os.path.exists(input_dir):
        # sample_submission dosyasÄ±nÄ± ara (csv veya parquet)
        possible_submission_files = [
            os.path.join(input_dir, 'sample_submission.csv'),
            os.path.join(input_dir, 'sample_submission.parquet'),
            os.path.join(input_dir, 'sampleSubmission.csv'),
            os.path.join(input_dir, 'sampleSubmission.parquet'),
            os.path.join(input_dir, 'SampleSubmission.csv'),
        ]

        for sub_file in possible_submission_files:
            if os.path.exists(sub_file):
                sample_submission_path = sub_file
                competition_input_dir = input_dir
                log(f"âœ“ Submission dosyasÄ± bulundu: {sub_file}")
                break

        # test_images dizini ara
        possible_test_dirs = [
            os.path.join(input_dir, 'test_images'),
            os.path.join(input_dir, 'test'),
            os.path.join(input_dir, 'images'),
        ]

        for test_dir in possible_test_dirs:
            if os.path.exists(test_dir):
                test_data_path = test_dir
                log(f"âœ“ Test gÃ¶rselleri dizini bulundu: {test_dir}")
                break

        # test.csv dosyasÄ±nÄ± da kontrol et (fallback iÃ§in)
        test_csv_path = os.path.join(input_dir, 'test.csv')
        if os.path.exists(test_csv_path):
            if not sample_submission_path:
                sample_submission_path = test_csv_path
                competition_input_dir = input_dir
                log(f"âœ“ test.csv bulundu (fallback olarak kullanÄ±lacak): {test_csv_path}")

        if sample_submission_path and test_data_path:
            break

# sample_submission dosyasÄ±nÄ± oku ve gerÃ§ek record_id'leri al
record_ids = []
if sample_submission_path:
    heartbeat("Submission dosyasÄ± okunuyor...")
    import pandas as pd

    # Dosya formatÄ±na gÃ¶re oku
    try:
        if sample_submission_path.endswith('.parquet'):
            heartbeat("Parquet dosyasÄ± okunuyor...")
            sample_df = pd.read_parquet(sample_submission_path)
            log(f"âœ“ Parquet dosyasÄ± okundu: {len(sample_df)} satÄ±r")
        else:
            sample_df = pd.read_csv(sample_submission_path)
            log(f"âœ“ CSV dosyasÄ± okundu: {len(sample_df)} satÄ±r")

        # record_id'leri Ã§Ä±kar (unique)
        if 'record_id' in sample_df.columns:
            # Standart format: record_id kolonu var
            record_ids = sorted(sample_df['record_id'].unique().tolist())
            log(f"âœ“ {len(record_ids)} adet record_id bulundu")
            log(f"   Ä°lk 5 record: {record_ids[:5]}")
        elif 'id' in sample_df.columns:
            # Alternatif format: id kolonu var (Ã¶rn: "record_id_time_lead")
            # id'den record_id'yi parse et (ilk underscore'a kadar)
            heartbeat("id kolonundan record_id'ler parse ediliyor...")
            sample_df['parsed_record_id'] = sample_df['id'].str.split('_').str[0]
            record_ids = sorted(sample_df['parsed_record_id'].unique().tolist())
            log(f"âœ“ {len(record_ids)} adet record_id parse edildi")
            log(f"   Ä°lk 5 record: {record_ids[:5]}")
            log(f"   Ã–rnek id format: {sample_df['id'].iloc[0]}")
        else:
            log("âŒ 'record_id' veya 'id' kolonu bulunamadÄ±!", "ERROR")
            log(f"   Mevcut kolonlar: {sample_df.columns.tolist()}", "ERROR")
            raise ValueError("Submission dosyasÄ± formatÄ± hatalÄ±")

    except Exception as e:
        log(f"âŒ Dosya okuma hatasÄ±: {e}", "ERROR")
        raise

else:
    log("âŒ sample_submission dosyasÄ± bulunamadÄ±!", "ERROR")
    log("LÃ¼tfen Kaggle yarÄ±ÅŸmasÄ±nÄ±n input datasÄ±nÄ± notebook'a ekleyin:", "ERROR")
    log("  1. Notebook ayarlarÄ±ndan 'Add Data' seÃ§in", "ERROR")
    log("  2. PhysioNet ECG yarÄ±ÅŸmasÄ±nÄ±n datasÄ±nÄ± ekleyin", "ERROR")
    raise FileNotFoundError("sample_submission dosyasÄ± bulunamadÄ±")

# Test gÃ¶rsellerini record_id'lere gÃ¶re eÅŸleÅŸtir
if test_data_path:
    heartbeat("Test gÃ¶rselleri eÅŸleÅŸtiriliyor...")
    test_images_dict = {}

    # TÃ¼m gÃ¶rselleri tara
    all_images = (
        list(Path(test_data_path).glob('*.png')) +
        list(Path(test_data_path).glob('*.jpg')) +
        list(Path(test_data_path).glob('*.jpeg')) +
        list(Path(test_data_path).glob('*.PNG')) +
        list(Path(test_data_path).glob('*.JPG'))
    )

    # record_id'lere gÃ¶re eÅŸleÅŸtir
    for img_path in all_images:
        record_id = img_path.stem  # dosya adÄ±ndan uzantÄ±yÄ± Ã§Ä±kar
        if record_id in record_ids:
            test_images_dict[record_id] = img_path

    log(f"âœ“ {len(test_images_dict)}/{len(record_ids)} gÃ¶rsel eÅŸleÅŸtirildi")

    if len(test_images_dict) == 0:
        log("âŒ HiÃ§bir test gÃ¶rseli bulunamadÄ±!", "ERROR")
        raise FileNotFoundError("Test gÃ¶rselleri bulunamadÄ±")

    USE_DUMMY_DATA = False
else:
    log("âŒ Test gÃ¶rselleri dizini bulunamadÄ±!", "ERROR")
    raise FileNotFoundError("Test gÃ¶rselleri dizini bulunamadÄ±")

# Ä°lk gÃ¶rseli gÃ¶rselleÅŸtir
if len(test_images_dict) > 0:
    heartbeat("Ã–rnek gÃ¶rsel yÃ¼kleniyor...")
    first_record_id = list(test_images_dict.keys())[0]
    first_image_path = test_images_dict[first_record_id]

    sample_img = cv2.imread(str(first_image_path))
    sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)

    heartbeat("GÃ¶rsel kaydediliyor...")
    plt.figure(figsize=(15, 10))
    plt.imshow(sample_img)
    plt.title(f"Ã–rnek ECG GÃ¶rÃ¼ntÃ¼sÃ¼: {first_image_path.name} (Record: {first_record_id})", fontsize=14, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    plt.savefig('/kaggle/working/sample_ecg_image.png', dpi=150, bbox_inches='tight')
    plt.close()
    log("âœ“ GÃ¶rsel kaydedildi: sample_ecg_image.png")

print()


# ============================================================================
# STEP 4: Model YÃ¼kleme veya Dummy Model OluÅŸturma
# ============================================================================
log("STEP 4: Model yÃ¼kleme", "START")
print("-" * 80)

# Model path'leri
possible_model_paths = [
    '/kaggle/input/ecg-model-weights/fold_0_best.pth',
    '/kaggle/input/ecg-model/best_model.pth',
    '/kaggle/input/physionet-model/fold_0_best.pth',
]

model_path = None
for path in possible_model_paths:
    heartbeat(f"Model kontrol ediliyor: {path}")
    if os.path.exists(path):
        model_path = path
        log(f"âœ“ Model bulundu: {path}")
        break

if model_path is None:
    log("âš ï¸ EÄŸitilmiÅŸ model bulunamadÄ±! DUMMY MODEL MODU", "WARNING")
    log("Not: Bu mod sadece test iÃ§indir. GerÃ§ek sonuÃ§lar iÃ§in eÄŸitilmiÅŸ model gerekir!")

    USE_REAL_MODEL = False

    # Dummy prediction fonksiyonu
    preprocessor = ECGImagePreprocessor()
    vectorizer = ECGVectorizer()

    def predict_image(image_path):
        """Dummy prediction - eÄŸitilmiÅŸ model olmadan"""
        heartbeat(f"Ä°ÅŸleniyor: {Path(image_path).name}")

        # Preprocessing yap
        preprocessed = preprocessor.preprocess(image_path, apply_normalization=False)

        # Random signal Ã¼ret
        num_leads = 12
        signal_length = 5000

        # Biraz daha gerÃ§ekÃ§i gÃ¶rÃ¼nmesi iÃ§in sinÃ¼zoidal bileÅŸenler
        t = np.linspace(0, 10, signal_length)
        dummy_signals = np.zeros((num_leads, signal_length))

        for i in range(num_leads):
            freq1 = 1.0 + i * 0.1
            freq2 = 10.0 + i * 0.5
            dummy_signals[i] = (
                0.8 * np.sin(2 * np.pi * freq1 * t) +
                0.2 * np.sin(2 * np.pi * freq2 * t) +
                0.1 * np.random.randn(signal_length)
            )

        return dummy_signals

else:
    log("âœ“ GerÃ§ek model kullanÄ±lÄ±yor")
    USE_REAL_MODEL = True

    try:
        heartbeat("Model yÃ¼kleniyor (bu biraz zaman alabilir)...")
        # Pipeline oluÅŸtur
        pipeline = ECGInferencePipeline(
            model_path=model_path,
            config=config,
            device=device
        )
        log("âœ… Model baÅŸarÄ±yla yÃ¼klendi!", "SUCCESS")

        def predict_image(image_path):
            """GerÃ§ek model ile prediction"""
            heartbeat(f"Predicting: {Path(image_path).name}")
            return pipeline.predict(
                image_path,
                correct_rotation=True,
                threshold=0.5,
                return_dict=False
            )

    except Exception as e:
        log(f"âŒ Model yÃ¼kleme hatasÄ±: {e}", "ERROR")
        log("Dummy mode'a geÃ§iliyor...", "WARNING")
        USE_REAL_MODEL = False

        preprocessor = ECGImagePreprocessor()

        def predict_image(image_path):
            heartbeat(f"Processing (dummy): {Path(image_path).name}")
            preprocessed = preprocessor.preprocess(image_path, apply_normalization=False)
            return np.random.randn(12, 5000) * 0.5

print()


# ============================================================================
# STEP 5: Test Prediction (HÄ±zlÄ± Kontrol)
# ============================================================================
log("STEP 5: Test prediction", "START")
print("-" * 80)

heartbeat("Ä°lk gÃ¶rsel Ã¼zerinde test prediction yapÄ±lÄ±yor...")

try:
    first_record_id = list(test_images_dict.keys())[0]
    first_image_path = test_images_dict[first_record_id]

    test_signal = predict_image(first_image_path)
    log(f"âœ“ Prediction tamamlandÄ± (Record: {first_record_id})")
    log(f"  Shape: {test_signal.shape}")
    log(f"  Range: [{test_signal.min():.3f}, {test_signal.max():.3f}] mV")
    log(f"  Mean: {test_signal.mean():.3f} mV")

    # GÃ¶rselleÅŸtir
    heartbeat("Sinyal gÃ¶rselleÅŸtiriliyor...")
    fig, axes = plt.subplots(4, 3, figsize=(20, 15))
    axes = axes.flatten()

    lead_names = config.data.lead_names
    time = np.arange(1000) / 500

    for i, lead_name in enumerate(lead_names):
        ax = axes[i]
        ax.plot(time, test_signal[i, :1000], 'b-', linewidth=0.8)
        ax.set_title(f'Lead {lead_name}', fontsize=12, fontweight='bold')
        ax.set_xlabel('Time (s)')
        ax.set_ylabel('Amplitude (mV)')
        ax.grid(True, alpha=0.3)

    plt.suptitle(f'Test Prediction - {first_record_id} (Ä°lk 2 saniye)', fontsize=16, fontweight='bold')
    plt.tight_layout()
    plt.savefig('/kaggle/working/test_prediction.png', dpi=150, bbox_inches='tight')
    plt.close()
    log("âœ“ GÃ¶rsel kaydedildi: test_prediction.png")

except Exception as e:
    log(f"âŒ Test prediction hatasÄ±: {e}", "ERROR")

print()


# ============================================================================
# STEP 6: Batch Prediction - Timeout-Safe Version
# ============================================================================
log("STEP 6: Batch prediction (Timeout-Safe)", "START")
print("-" * 80)

predictions = {}

log(f"Toplam {len(record_ids)} record iÅŸlenecek")
log(f"  â€¢ GÃ¶rseli bulunan: {len(test_images_dict)}")
log(f"  â€¢ GÃ¶rseli bulunamayan: {len(record_ids) - len(test_images_dict)}")

# Batch boyutu (her N gÃ¶rselde bir checkpoint)
CHECKPOINT_INTERVAL = 10
HEARTBEAT_INTERVAL = 5

success_count = 0
error_count = 0
missing_count = 0

# Progress bar ile iÅŸle - TÃœM record_id'ler iÃ§in
pbar = tqdm(record_ids, desc="Processing records", unit="record")

for idx, record_id in enumerate(pbar, 1):
    try:
        # Heartbeat her N kayÄ±tta
        if idx % HEARTBEAT_INTERVAL == 0:
            heartbeat(f"Ä°ÅŸlenen: {idx}/{len(record_ids)} ({success_count} baÅŸarÄ±lÄ±, {missing_count} eksik, {error_count} hatalÄ±)")

        # EÄŸer gÃ¶rsel varsa, gerÃ§ek prediction yap
        if record_id in test_images_dict:
            image_path = test_images_dict[record_id]
            signals = predict_image(image_path)
            predictions[record_id] = signals
            success_count += 1
        else:
            # GÃ¶rsel yoksa, sÄ±fÄ±r deÄŸerli signal oluÅŸtur (uyarÄ± ver)
            if missing_count == 0:
                log(f"âš ï¸ GÃ¶rseli bulunamayan kayÄ±tlar iÃ§in sÄ±fÄ±r deÄŸerli signal oluÅŸturuluyor", "WARNING")
            signals = np.zeros((12, 5000))
            predictions[record_id] = signals
            missing_count += 1

        # Progress bar gÃ¼ncelle
        pbar.set_postfix({'success': success_count, 'missing': missing_count, 'errors': error_count})

        # Checkpoint kaydet
        if idx % CHECKPOINT_INTERVAL == 0:
            log(f"ğŸ’¾ Checkpoint: {idx}/{len(record_ids)} iÅŸlendi")
            # Ä°steÄŸe baÄŸlÄ±: ara sonuÃ§larÄ± kaydet
            checkpoint_file = f'/kaggle/working/checkpoint_{idx}.txt'
            with open(checkpoint_file, 'w') as f:
                f.write(f"Processed: {idx}\nSuccess: {success_count}\nMissing: {missing_count}\nErrors: {error_count}")

    except Exception as e:
        error_count += 1
        if error_count <= 5:
            log(f"âŒ Hata (record: {record_id}): {e}", "ERROR")
        # Hata durumunda da sÄ±fÄ±r deÄŸerli signal ekle
        predictions[record_id] = np.zeros((12, 5000))
        pbar.set_postfix({'success': success_count, 'missing': missing_count, 'errors': error_count})

pbar.close()

log(f"âœ… Batch processing tamamlandÄ±!", "SUCCESS")
log(f"   BaÅŸarÄ±lÄ±: {success_count}/{len(record_ids)}")
if missing_count > 0:
    log(f"   GÃ¶rseli yok: {missing_count}/{len(record_ids)}", "WARNING")
if error_count > 0:
    log(f"   HatalÄ±: {error_count}/{len(record_ids)}", "WARNING")

# Ä°statistikler
if len(predictions) > 0:
    heartbeat("Ä°statistikler hesaplanÄ±yor...")
    all_signals = np.stack(list(predictions.values()))
    log(f"\nğŸ“Š Prediction Ä°statistikleri:")
    log(f"   Shape: {all_signals.shape}")
    log(f"   Min: {all_signals.min():.3f} mV")
    log(f"   Max: {all_signals.max():.3f} mV")
    log(f"   Mean: {all_signals.mean():.3f} mV")
    log(f"   Std: {all_signals.std():.3f} mV")

print()


# ============================================================================
# STEP 7: Submission File OluÅŸtur
# ============================================================================
log("STEP 7: Kaggle submission dosyasÄ± oluÅŸturma", "START")
print("-" * 80)

lead_names = config.data.lead_names

heartbeat("Submission formatÄ± hazÄ±rlanÄ±yor...")
rows = []

# Progress bar ile submission oluÅŸtur
# Format: id = "{record_id}_{time_idx}_{lead_name}", value = signal_value
total_rows = len(predictions) * len(lead_names) * 5000
log(f"Toplam {total_rows:,} satÄ±r oluÅŸturulacak")
log(f"Format: id = {{record_id}}_{{time}}_{{lead}}, value = signal_value")

row_count = 0
for record_id, signals in predictions.items():
    heartbeat(f"Submission oluÅŸturuluyor: {record_id}")

    for lead_idx, lead_name in enumerate(lead_names):
        for time_idx in range(signals.shape[1]):
            # ID formatÄ±: {record_id}_{time_idx}_{lead_name}
            row_id = f"{record_id}_{time_idx}_{lead_name}"
            rows.append({
                'id': row_id,
                'value': float(signals[lead_idx, time_idx])
            })

            row_count += 1
            # Her 100k satÄ±rda heartbeat
            if row_count % 100000 == 0:
                heartbeat(f"OluÅŸturulan satÄ±r: {row_count:,}/{total_rows:,}")

heartbeat("DataFrame oluÅŸturuluyor...")
submission_df = pd.DataFrame(rows)

# Kaydet
heartbeat("CSV dosyasÄ± kaydediliyor...")
submission_path = '/kaggle/working/submission.csv'
submission_df.to_csv(submission_path, index=False)

log(f"âœ… Submission dosyasÄ± oluÅŸturuldu!", "SUCCESS")
log(f"   Path: {submission_path}")
log(f"   Toplam satÄ±r: {len(submission_df):,}")
log(f"   Toplam record: {len(predictions)}")
log(f"   Dosya boyutu: {os.path.getsize(submission_path) / (1024*1024):.2f} MB")

# Ã–nizleme
log(f"\nğŸ“‹ Submission Ã–nizlemesi (ilk 20 satÄ±r):")
print(submission_df.head(20).to_string())

print()


# ============================================================================
# STEP 8: Submission Validation
# ============================================================================
log("STEP 8: Submission validation", "START")
print("-" * 80)

heartbeat("Submission dosyasÄ± kontrol ediliyor...")

# Boyut kontrolÃ¼
log(f"âœ“ Toplam satÄ±r: {len(submission_df):,}")
log(f"âœ“ Kolonlar: {list(submission_df.columns)}")

# Kolon kontrolÃ¼
expected_columns = ['id', 'value']
if list(submission_df.columns) == expected_columns:
    log(f"âœ“ Kolonlar doÄŸru: {expected_columns}")
else:
    log(f"âš ï¸ Kolon uyuÅŸmazlÄ±ÄŸÄ±! Beklenen: {expected_columns}, Mevcut: {list(submission_df.columns)}", "WARNING")

# Eksik deÄŸer kontrolÃ¼
missing = submission_df.isnull().sum().sum()
if missing > 0:
    log(f"âš ï¸ {missing} eksik deÄŸer bulundu!", "WARNING")
else:
    log(f"âœ“ Eksik deÄŸer yok")

# ID formatÄ± kontrolÃ¼ (Ã¶rnek kontrol)
sample_id = submission_df['id'].iloc[0]
if '_' in sample_id:
    log(f"âœ“ ID formatÄ± doÄŸru (Ã¶rnek: {sample_id})")
else:
    log(f"âš ï¸ ID formatÄ± hatalÄ± (Ã¶rnek: {sample_id})", "WARNING")

# Record sayÄ±sÄ± (id'lerden parse et)
unique_records = submission_df['id'].str.split('_').str[0].nunique()
log(f"âœ“ Unique record sayÄ±sÄ±: {unique_records}")

# DeÄŸer aralÄ±ÄŸÄ± kontrolÃ¼
val_min = submission_df['value'].min()
val_max = submission_df['value'].max()
val_mean = submission_df['value'].mean()
log(f"âœ“ DeÄŸer aralÄ±ÄŸÄ±: [{val_min:.3f}, {val_max:.3f}] mV")
log(f"âœ“ Ortalama deÄŸer: {val_mean:.3f} mV")

# Dosya boyutu
file_size_mb = os.path.getsize(submission_path) / (1024 * 1024)
log(f"âœ“ Dosya boyutu: {file_size_mb:.2f} MB")

# NaN/Inf kontrolÃ¼
has_inf = np.isinf(submission_df['value']).any()
if has_inf:
    log("âš ï¸ Infinity deÄŸerleri tespit edildi!", "WARNING")
else:
    log("âœ“ Infinity deÄŸeri yok")

print("\n" + "=" * 80)

if missing == 0 and list(submission_df.columns) == expected_columns and not has_inf:
    log("âœ…âœ…âœ… SUBMISSION HAZIR! SUBMIT EDEBÄ°LÄ°RSÄ°NÄ°Z! âœ…âœ…âœ…", "SUCCESS")
else:
    log("âš ï¸ Submission'da bazÄ± sorunlar var, lÃ¼tfen kontrol edin", "WARNING")

print("=" * 80)
print()


# ============================================================================
# STEP 9: GÃ¶rselleÅŸtirme
# ============================================================================
log("STEP 9: SonuÃ§ gÃ¶rselleÅŸtirme", "START")
print("-" * 80)

if len(predictions) > 0:
    # Rastgele bir record seÃ§
    import random
    random_record = random.choice(list(predictions.keys()))
    signals = predictions[random_record]

    heartbeat(f"GÃ¶rselleÅŸtirilen record: {random_record}")

    # TÃ¼m 12 lead'i gÃ¶rselleÅŸtir
    fig, axes = plt.subplots(4, 3, figsize=(20, 15))
    axes = axes.flatten()

    for i, lead_name in enumerate(lead_names):
        heartbeat(f"Lead {lead_name} Ã§iziliyor...")
        ax = axes[i]

        # TÃ¼m sinyali Ã§iz
        time = np.arange(signals.shape[1]) / 500
        ax.plot(time, signals[i], 'b-', linewidth=0.5)

        ax.set_title(f'Lead {lead_name}', fontsize=14, fontweight='bold')
        ax.set_xlabel('Time (s)', fontsize=10)
        ax.set_ylabel('Amplitude (mV)', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.set_xlim([0, 10])

        # Ä°statistikler
        stats_text = f'Min: {signals[i].min():.2f}\nMax: {signals[i].max():.2f}\nMean: {signals[i].mean():.2f}'
        ax.text(0.02, 0.98, stats_text, transform=ax.transAxes,
                fontsize=8, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.suptitle(f'12-Lead ECG Signal - Record: {random_record}',
                 fontsize=18, fontweight='bold', y=0.995)
    plt.tight_layout()

    heartbeat("GÃ¶rsel kaydediliyor...")
    plt.savefig('/kaggle/working/ecg_visualization.png', dpi=150, bbox_inches='tight')
    plt.close()
    log("âœ“ GÃ¶rsel kaydedildi: ecg_visualization.png")

    # Per-lead istatistikler
    log("\nğŸ“Š Lead Ä°statistikleri:")
    print("-" * 80)
    print(f"{'Lead':<6} {'Min':>10} {'Max':>10} {'Mean':>10} {'Std':>10}")
    print("-" * 80)
    for i, lead_name in enumerate(lead_names):
        print(f"{lead_name:<6} {signals[i].min():>10.3f} {signals[i].max():>10.3f} "
              f"{signals[i].mean():>10.3f} {signals[i].std():>10.3f}")

print()


# ============================================================================
# Ã–ZET VE SONUÃ‡
# ============================================================================
log("=" * 80)
log("ğŸ‰ PIPELINE TAMAMLANDI!", "SUCCESS")
log("=" * 80)

log(f"\nğŸ“Š Ã–ZET:")
log(f"   â€¢ Toplam record sayÄ±sÄ±: {len(record_ids)}")
log(f"   â€¢ GerÃ§ek gÃ¶rsellerden tahmin: {success_count}")
if missing_count > 0:
    log(f"   â€¢ âš ï¸ GÃ¶rseli olmayan (sÄ±fÄ±r deÄŸer): {missing_count}")
if error_count > 0:
    log(f"   â€¢ âš ï¸ HatalÄ± (sÄ±fÄ±r deÄŸer): {error_count}")
log(f"   â€¢ Submission satÄ±r sayÄ±sÄ±: {len(submission_df):,}")
log(f"   â€¢ Model tipi: {'GERÃ‡EK MODEL' if USE_REAL_MODEL else 'DUMMY MODEL (Test)'}")
log(f"   â€¢ Submission dosyasÄ±: {submission_path}")
log(f"   â€¢ Dosya boyutu: {file_size_mb:.2f} MB")

log(f"\nğŸ“ OLUÅTURULAN DOSYALAR:")
output_files = [
    '/kaggle/working/submission.csv',
    '/kaggle/working/ecg_visualization.png',
    '/kaggle/working/test_prediction.png',
    '/kaggle/working/sample_ecg_image.png',
]

for file_path in output_files:
    if os.path.exists(file_path):
        size = os.path.getsize(file_path) / 1024
        log(f"   âœ“ {file_path} ({size:.1f} KB)")

log(f"\nğŸš€ SONRAKI ADIMLAR:")
if not USE_REAL_MODEL:
    log("   1. âš ï¸ DUMMY MODEL KULLANILDI! GerÃ§ek sonuÃ§lar iÃ§in:")
    log("      - Model eÄŸitin: scripts/train.py")
    log("      - EÄŸitilmiÅŸ modeli Kaggle'a dataset olarak yÃ¼kleyin")
    log("      - Bu scripti tekrar Ã§alÄ±ÅŸtÄ±rÄ±n")
    log("")

if missing_count > 0:
    log("   âš ï¸ UYARI: BazÄ± kayÄ±tlarÄ±n gÃ¶rselleri bulunamadÄ±!")
    log("      - Bu kayÄ±tlar iÃ§in sÄ±fÄ±r deÄŸerli signal kullanÄ±ldÄ±")
    log("      - GerÃ§ek yarÄ±ÅŸmada tÃ¼m gÃ¶rsellerin olduÄŸundan emin olun")
    log("")

log("   â€¢ submission.csv dosyasÄ±nÄ± indirin")
log("   â€¢ Kaggle Competition sayfasÄ±na gidin")
log("   â€¢ 'Submit Predictions' butonuna tÄ±klayÄ±n")
log("   â€¢ submission.csv dosyasÄ±nÄ± yÃ¼kleyin")
log("   â€¢ SonuÃ§larÄ± bekleyin!")

log("\n" + "=" * 80)
log("âœ… Script baÅŸarÄ±yla tamamlandÄ±!", "SUCCESS")
log(f"â±ï¸ Toplam sÃ¼re: {time_module.time() - START_TIME:.2f} saniye")
log("=" * 80)
